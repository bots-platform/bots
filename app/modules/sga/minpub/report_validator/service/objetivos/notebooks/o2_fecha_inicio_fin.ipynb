{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_info_columns', 10000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_decimal_part(df, column):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame column from float (or numeric string) to a string\n",
    "    by removing the decimal part (i.e. converting 13.5 to \"13\", 12.0 to \"12\").\n",
    "    Non-numeric values are converted to NaN and then to an empty string.\n",
    "    \"\"\"\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: str(int(x)) if pd.notnull(x) else '')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null_values(df, fill_str=\"\", fill_float=0.0, fill_datetime=\"\"):\n",
    "    \"\"\"\n",
    "    Fill null values in DataFrame columns based on data type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        fill_str (str): Value to replace nulls in object/string columns. Default is \"\".\n",
    "        fill_float (float): Value to replace nulls in float columns. Default is 0.0.\n",
    "        fill_datetime: Value to replace nulls in datetime columns. \n",
    "                       Default is \"\", but you can also pass a default datetime.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with nulls handled.\n",
    "    \"\"\"\n",
    "\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        df[col] = df[col].fillna(fill_str).astype(str)\n",
    "    \n",
    "\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].fillna(fill_float)\n",
    "        \n",
    "\n",
    "    datetime_cols = df.select_dtypes(include=['datetime64[ns]']) \n",
    "    for col in datetime_cols:\n",
    "        df[col] = df[col].fillna(fill_datetime)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_dataframe_summary(df):\n",
    "    \"\"\"\n",
    "    Returns a summary DataFrame for the given DataFrame.\n",
    "    \n",
    "    The summary includes:\n",
    "      - Data Type\n",
    "      - Non Null Count\n",
    "      - Null Count\n",
    "      - Null Percentage\n",
    "      - Unique Values count\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Data Type': df.dtypes,\n",
    "        'Non Null Count': df.count(),\n",
    "        'Null Count': df.isna().sum(),\n",
    "        'Null Percentage': (df.isna().sum() / len(df) * 100).round(2),\n",
    "        'Unique Values': [df[col].nunique() for col in df.columns],\n",
    "    })\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd().parent.parent.parent.parent.parent.parent.parent.parent\n",
    "SAVE_DIR_EXTRACT_EXCEL = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"excel\"/ \"CORTE 3 _ 10-03-25 AL 16-03-25_20250328_182204.xlsx\"\n",
    "SAVE_DIR_EXTRACT_SGA_335 = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sga_335\" / \"sga_reporte_10-03-2025_16-03-2025_20250402_112253.xlsx\"\n",
    "CID_CUISMP_PATH = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sharepoint_cid_cuismp\" / \"MINPU - CID-CUISMP - AB.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corte_excel = pd.read_excel(SAVE_DIR_EXTRACT_EXCEL, skipfooter=2, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df_excel2 = get_dataframe_summary(df_corte_excel)\n",
    "df_corte_excel = cut_decimal_part(df_corte_excel, 'CUISMP')\n",
    "\n",
    "info_df_excel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corte_excel = handle_null_values(df_corte_excel)\n",
    "info_df_excel2 = get_dataframe_summary(df_corte_excel)\n",
    "info_df_excel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_corte_excel[df_corte_excel['TICKET'] == 21786971 ]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335 = pd.read_excel(SAVE_DIR_EXTRACT_SGA_335)\n",
    "info_df_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_df_335\n",
    "row = df_sga_dinamico_335[df_sga_dinamico_335['nro_incidencia'] == 21786971]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sga_dinamico_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335['interrupcion_inicio'] = pd.to_datetime(df_sga_dinamico_335['interrupcion_inicio'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['interrupcion_fin'] = pd.to_datetime(df_sga_dinamico_335['interrupcion_fin'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fecha_comunicacion_cliente'] = pd.to_datetime(df_sga_dinamico_335['fecha_comunicacion_cliente'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fecha_generacion'] = pd.to_datetime(df_sga_dinamico_335['fecha_generacion'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fg_padre'] = pd.to_datetime(df_sga_dinamico_335['fg_padre'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['hora_sistema'] = pd.to_datetime(df_sga_dinamico_335['hora_sistema'], errors='coerce', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_sga_dinamico_335['Expected_Inicio'] = np.where(df_sga_dinamico_335['masivo'] == \"Si\",\n",
    "                                     df_sga_dinamico_335['fecha_generacion'],\n",
    "                                     df_sga_dinamico_335['interrupcion_inicio'])\n",
    "df_sga_dinamico_335.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sga_dinamico_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sga_335_corte_excel(\n",
    "    df_corte_excel: pd.DataFrame, \n",
    "    df_sga_dinamico_335: pd.DataFrame, \n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Common merge function for Objective 1.\n",
    "    \n",
    "    Merges:\n",
    "      - corte-excel  with sga_dinamico_335 on 'nro_incidencia'\n",
    "\n",
    "    Returns a merged DataFrame with common columns needed.\n",
    "    \"\"\"\n",
    "\n",
    "    df_corte_excel = df_corte_excel.rename(columns={'TICKET':'nro_incidencia'})\n",
    "   \n",
    "    df_corte_excel['nro_incidencia'] = df_corte_excel['nro_incidencia'].astype(str)\n",
    "    df_sga_dinamico_335['nro_incidencia'] = df_sga_dinamico_335['nro_incidencia'].astype(str)\n",
    "\n",
    "    merged_sga335_excel = pd.merge(\n",
    "        df_corte_excel,\n",
    "        df_sga_dinamico_335,\n",
    "        on='nro_incidencia',\n",
    "        how='left',\n",
    "        suffixes=('_corte_excel', '_sga_dinamico_335')\n",
    "    )\n",
    "\n",
    "    return merged_sga335_excel\n",
    "df_merge_sga_335_corte_excel = merge_sga_335_corte_excel(df_corte_excel, df_sga_dinamico_335)\n",
    "df_merge_sga_335_corte_excel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_merge_sga_335_corte_excel[df_merge_sga_335_corte_excel['nro_incidencia'] == \"21787031\" ]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_fecha_inicio_fin(merged_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Valida las columnas de fechas en CORTE EXCEL y las compara con las del REPORTE DINÁMICO 335.\n",
    "    \n",
    "    Reglas:\n",
    "      1) En CORTE EXCEL, “FECHA Y HORA INICIO” y “FECHA Y HORA FIN” no deben ser vacías.\n",
    "      2) A partir del “nro_incidencia” en REPORTE DINÁMICO 335:\n",
    "            - Si la columna “Masivo” tiene el valor “Si”, se utiliza “FECHA_GENERACION” como fecha de inicio.\n",
    "            - En caso contrario, se utiliza “INTERRUPCION_INICIO”.\n",
    "      3) Se compara:\n",
    "            - La fecha esperada de inicio (según lo anterior) con “FECHA Y HORA INICIO” de CORTE EXCEL.\n",
    "            - “INTERRUPCION_FIN” de REPORTE DINÁMICO 335 con “FECHA Y HORA FIN” de CORTE EXCEL.\n",
    "      4) Ambas comparaciones deben coincidir para considerarse válidas.\n",
    "    \n",
    "    Devuelve un DataFrame con las siguientes columnas adicionales:\n",
    "      - 'NotEmpty': Flag que indica que las fechas de CORTE EXCEL no son vacías.\n",
    "      - 'Fecha_Inicio_match': Flag que indica si la fecha de inicio es correcta.\n",
    "      - 'Fecha_Fin_match': Flag que indica si la fecha de fin es correcta.\n",
    "      - 'Validation_OK': True si todas las condiciones se cumplen.\n",
    "      - 'fail_count': Número de validaciones fallidas.\n",
    "    \"\"\"\n",
    "    df = merged_df.copy()\n",
    "\n",
    "    df['NotEmpty'] = df['FECHA Y HORA INICIO'].notna() & df['FECHA Y HORA FIN'].notna()\n",
    "\n",
    "    df['Expected_Inicio'] = np.where(df['masivo'] == \"Si\",\n",
    "                                     df['fecha_generacion'],\n",
    "                                     df['interrupcion_inicio'])\n",
    "\n",
    "    df['Fecha_Inicio_match'] = df['Expected_Inicio'] == df['FECHA Y HORA INICIO']\n",
    "\n",
    "    df['Fecha_Fin_match'] = df['interrupcion_fin'] == df['FECHA Y HORA FIN']\n",
    "\n",
    "    df['Validation_OK'] = df['NotEmpty'] & df['Fecha_Inicio_match'] & df['Fecha_Fin_match']\n",
    "\n",
    "    df['fail_count'] = (~df['NotEmpty']).astype(int) + (~df['Fecha_Inicio_match']).astype(int) + (~df['Fecha_Fin_match']).astype(int)\n",
    "\n",
    "    return df\n",
    "df_validation_fecha_inicio_fin = validation_fecha_inicio_fin(df_merge_sga_335_corte_excel)\n",
    "df_validation_fecha_inicio_fin.head(1)\n",
    "row = df_validation_fecha_inicio_fin[df_validation_fecha_inicio_fin['nro_incidencia'] == '21787031']\n",
    "row\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
