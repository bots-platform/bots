{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_info_columns', 10000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_decimal_part(df, column):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame column from float (or numeric string) to a string\n",
    "    by removing the decimal part (i.e. converting 13.5 to \"13\", 12.0 to \"12\").\n",
    "    Non-numeric values are converted to NaN and then to an empty string.\n",
    "    \"\"\"\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: str(int(x)) if pd.notnull(x) else '')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_hhmm(hours_float):\n",
    "    hours = int(hours_float)\n",
    "    minutes = int(round((hours_float - hours)*60))\n",
    "    return f\"{hours}:{minutes:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_hhmm(total_seconds):\n",
    "    hours = total_seconds // 3600\n",
    "    minutes = (total_seconds % 3600) // 60\n",
    "    return f\"{hours}:{minutes:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null_values(df, fill_str=\"\", fill_float=0.0, fill_datetime=\"\"):\n",
    "    \"\"\"\n",
    "    Fill null values in DataFrame columns based on data type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        fill_str (str): Value to replace nulls in object/string columns. Default is \"\".\n",
    "        fill_float (float): Value to replace nulls in float columns. Default is 0.0.\n",
    "        fill_datetime: Value to replace nulls in datetime columns. \n",
    "                       Default is \"\", but you can also pass a default datetime.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with nulls handled.\n",
    "    \"\"\"\n",
    "\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        df[col] = df[col].fillna(fill_str).astype(str)\n",
    "    \n",
    "\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].fillna(fill_float)\n",
    "        \n",
    "\n",
    "    datetime_cols = df.select_dtypes(include=['datetime64[ns]']) \n",
    "    for col in datetime_cols:\n",
    "        df[col] = df[col].fillna(fill_datetime)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_dataframe_summary(df):\n",
    "    \"\"\"\n",
    "    Returns a summary DataFrame for the given DataFrame.\n",
    "    \n",
    "    The summary includes:\n",
    "      - Data Type\n",
    "      - Non Null Count\n",
    "      - Null Count\n",
    "      - Null Percentage\n",
    "      - Unique Values count\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Data Type': df.dtypes,\n",
    "        'Non Null Count': df.count(),\n",
    "        'Null Count': df.isna().sum(),\n",
    "        'Null Percentage': (df.isna().sum() / len(df) * 100).round(2),\n",
    "        'Unique Values': [df[col].nunique() for col in df.columns],\n",
    "    })\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DIR = Path.cwd().parent.parent.parent.parent.parent.parent.parent.parent\n",
    "# SAVE_DIR_EXTRACT_EXCEL = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"excel\"/ \"CORTE 1 - 23.03.25 AL 30.03.25_20250407_140635.xlsx\"\n",
    "# SAVE_DIR_EXTRACT_SGA_335 = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sga_335\" / \"sga_reporte_10-03-2025_16-03-2025_20250402_112253.xlsx\"\n",
    "# CID_CUISMP_PATH = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sharepoint_cid_cuismp\" / \"MINPU - CID-CUISMP - AB.xlsx\"\n",
    "\n",
    "BASE_DIR = Path.cwd().parent.parent.parent.parent.parent.parent.parent.parent\n",
    "SAVE_DIR_EXTRACT_EXCEL = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"excel\"/ \"CORTE 2_20250410_194426.xlsx\"\n",
    "SAVE_DIR_EXTRACT_SGA_335 = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sga_335\" / \"sga_reporte_30-03-2025_04-04-2025_20250410_194858.xlsx\"\n",
    "CID_CUISMP_PATH = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sharepoint_cid_cuismp\" / \"MINPU - CID-CUISMP - AB.xlsx\"\n",
    "DIR_PARADAS_RELOJ = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"pausa_cliente\" / \"sga_reporte_30-03-2025_04-04-2025_20250410_195338.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corte_excel = pd.read_excel(SAVE_DIR_EXTRACT_EXCEL, skipfooter=2, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df_excel2 = get_dataframe_summary(df_corte_excel)\n",
    "df_corte_excel = cut_decimal_part(df_corte_excel, 'CUISMP')\n",
    "\n",
    "info_df_excel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corte_excel = handle_null_values(df_corte_excel)\n",
    "info_df_excel2 = get_dataframe_summary(df_corte_excel)\n",
    "info_df_excel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_corte_excel[df_corte_excel['TICKET'] == 21784197 ]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335 = pd.read_excel(SAVE_DIR_EXTRACT_SGA_335)\n",
    "info_df_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_df_335\n",
    "#row = df_sga_dinamico_335[df_sga_dinamico_335['nro_incidencia'] == 21786971]\n",
    "#row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sga_dinamico_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335['interrupcion_inicio'] = pd.to_datetime(df_sga_dinamico_335['interrupcion_inicio'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['interrupcion_fin'] = pd.to_datetime(df_sga_dinamico_335['interrupcion_fin'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fecha_comunicacion_cliente'] = pd.to_datetime(df_sga_dinamico_335['fecha_comunicacion_cliente'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fecha_generacion'] = pd.to_datetime(df_sga_dinamico_335['fecha_generacion'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fg_padre'] = pd.to_datetime(df_sga_dinamico_335['fg_padre'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['hora_sistema'] = pd.to_datetime(df_sga_dinamico_335['hora_sistema'], errors='coerce', dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335 = handle_null_values(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335['tipificacion_interrupcion_hhmm'] = df_sga_dinamico_335['tipificacion_interrupcion'].apply(float_to_hhmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_sga_dinamico_335['Expected_Inicio'] = np.where(df_sga_dinamico_335['masivo'] == \"Si\",\n",
    "                                     df_sga_dinamico_335['fecha_generacion'],\n",
    "                                     df_sga_dinamico_335['interrupcion_inicio'])\n",
    "df_sga_dinamico_335.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sga_dinamico_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sga_335_corte_excel(\n",
    "    df_corte_excel: pd.DataFrame, \n",
    "    df_sga_dinamico_335: pd.DataFrame, \n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Common merge function for Objective 1.\n",
    "    \n",
    "    Merges:\n",
    "      - corte-excel  with sga_dinamico_335 on 'nro_incidencia'\n",
    "\n",
    "    Returns a merged DataFrame with common columns needed.\n",
    "    \"\"\"\n",
    "\n",
    "    df_corte_excel = df_corte_excel.rename(columns={'TICKET':'nro_incidencia'})\n",
    "   \n",
    "    df_corte_excel['nro_incidencia'] = df_corte_excel['nro_incidencia'].astype(str)\n",
    "    df_sga_dinamico_335['nro_incidencia'] = df_sga_dinamico_335['nro_incidencia'].astype(str)\n",
    "\n",
    "    merged_sga335_excel = pd.merge(\n",
    "        df_corte_excel,\n",
    "        df_sga_dinamico_335,\n",
    "        on='nro_incidencia',\n",
    "        how='left',\n",
    "        suffixes=('_corte_excel', '_sga_dinamico_335')\n",
    "    )\n",
    "\n",
    "    return merged_sga335_excel\n",
    "\n",
    "df_merge_sga_335_corte_excel = merge_sga_335_corte_excel(df_corte_excel, df_sga_dinamico_335)\n",
    "#df_merge_sga_335_corte_excel\n",
    "info = get_dataframe_summary(df_merge_sga_335_corte_excel)\n",
    "#info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_sga_335_corte_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_merge_sga_335_corte_excel[df_merge_sga_335_corte_excel['nro_incidencia'] == \"21784197\" ]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validation_fin_inicio_HHMM(merged_df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = merged_df.copy()\n",
    "    \n",
    "    df['start_335'] = np.where(df['masivo'] == \"Si\",\n",
    "                                     df['fecha_generacion'],\n",
    "                                     df['interrupcion_inicio'])\n",
    "    \n",
    "    df['diff_335_sec'] = (df['interrupcion_fin'] - df['start_335']).dt.total_seconds()\n",
    "    # df['diff_335_sec_hhmm'] = df['diff_335_sec'].apply(seconds_to_hhmm)\n",
    "    df['diff_corte_sec'] = (df['FECHA Y HORA FIN'] - df['FECHA Y HORA INICIO']).dt.total_seconds()\n",
    "\n",
    "    def parse_hhmm_to_minutes(hhmm_str):\n",
    "        if pd.isna(hhmm_str):\n",
    "            return np.nan\n",
    "        try:\n",
    "            h,m = str(hhmm_str).split(':')\n",
    "            total_minutes = int(h) * 60 + int(m)\n",
    "            print(f\"Converted {hhmm_str} to {total_minutes} seconds\")\n",
    "            return total_minutes\n",
    "        except Exception as e: \n",
    "            print(f\"Error with {hhmm_str}: {e}\")\n",
    "            return np.nan\n",
    "    \n",
    "    df['FIN-INICIO (HH:MM)_trimed'] = df['FIN-INICIO (HH:MM)'].apply(\n",
    "    lambda x: str(x)[:5] if isinstance(x, str) and x.endswith(\":00\") else x\n",
    "    )\n",
    "\n",
    "    df['fin_inicio_hhmm_column_corte_to_seconds'] = df['FIN-INICIO (HH:MM)_trimed'].apply(parse_hhmm_to_minutes)\n",
    "        \n",
    "\n",
    "\n",
    "    df['non_negative_335'] = df['diff_335_sec'] >= 0\n",
    "    df['non_negative_corte'] = df['diff_corte_sec'] >= 0\n",
    "\n",
    "    df['non_negative_fin_inicio_column_corte_hhmm_to_seconds'] = df['fin_inicio_hhmm_column_corte_to_seconds'] >= 0\n",
    "\n",
    "    tolerance = 1e-9\n",
    "\n",
    "    df['match_335_corte'] = (abs(df['diff_335_sec'] - df['diff_corte_sec']) < tolerance  )\n",
    "    df['match_corte_fin_inicio_hhmm_column'] = (abs(df['diff_corte_sec'] - df['fin_inicio_hhmm_column_corte_to_seconds']) < tolerance)\n",
    "\n",
    "    df['Validation_OK'] = (\n",
    "        df['non_negative_335'] &\n",
    "        df['non_negative_corte'] &\n",
    "        df['non_negative_fin_inicio_column_corte_hhmm_to_seconds'] &\n",
    "        df['match_335_corte'] &\n",
    "        df['match_corte_fin_inicio_hhmm_column']\n",
    "    )\n",
    "\n",
    "    df['fail_count'] = (\n",
    "        (~df['non_negative_335']).astype(int) +\n",
    "        (~df['non_negative_corte']).astype(int) +\n",
    "        (~df['non_negative_fin_inicio_column_corte_hhmm_to_seconds']).astype(int)+\n",
    "        (~df['match_335_corte']).astype(int) +\n",
    "        (~df['match_corte_fin_inicio_hhmm_column']).astype(int)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_validation_fecha_inicio_fin_HHMM = validation_fin_inicio_HHMM(df_merge_sga_335_corte_excel)\n",
    "df_validation_fecha_inicio_fin_HHMM.head(1)\n",
    "row = df_validation_fecha_inicio_fin_HHMM[df_validation_fecha_inicio_fin_HHMM['nro_incidencia'] == '21784197']\n",
    "row\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
