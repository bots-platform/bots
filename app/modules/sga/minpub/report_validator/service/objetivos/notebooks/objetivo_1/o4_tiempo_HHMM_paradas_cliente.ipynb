{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_info_columns', 10000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_decimal_part(df, column):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame column from float (or numeric string) to a string\n",
    "    by removing the decimal part (i.e. converting 13.5 to \"13\", 12.0 to \"12\").\n",
    "    Non-numeric values are converted to NaN and then to an empty string.\n",
    "    \"\"\"\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "    df[column] = df[column].apply(lambda x: str(int(x)) if pd.notnull(x) else '')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_hhmm(hours_float):\n",
    "    hours = int(hours_float)\n",
    "    minutes = int(round((hours_float - hours)*60))\n",
    "    return f\"{hours}:{minutes:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_hhmm(total_seconds):\n",
    "    hours = total_seconds // 3600\n",
    "    minutes = (total_seconds % 3600) // 60\n",
    "    return f\"{hours}:{minutes:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_null_values(df, fill_str=\"\", fill_float=0.0, fill_datetime=\"\"):\n",
    "    \"\"\"\n",
    "    Fill null values in DataFrame columns based on data type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        fill_str (str): Value to replace nulls in object/string columns. Default is \"\".\n",
    "        fill_float (float): Value to replace nulls in float columns. Default is 0.0.\n",
    "        fill_datetime: Value to replace nulls in datetime columns. \n",
    "                       Default is \"\", but you can also pass a default datetime.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with nulls handled.\n",
    "    \"\"\"\n",
    "\n",
    "    obj_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        df[col] = df[col].fillna(fill_str).astype(str)\n",
    "    \n",
    "\n",
    "    float_cols = df.select_dtypes(include=['float64']).columns\n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].fillna(fill_float)\n",
    "        \n",
    "\n",
    "    datetime_cols = df.select_dtypes(include=['datetime64[ns]']) \n",
    "    for col in datetime_cols:\n",
    "        df[col] = df[col].fillna(fill_datetime)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_dataframe_summary(df):\n",
    "    \"\"\"\n",
    "    Returns a summary DataFrame for the given DataFrame.\n",
    "    \n",
    "    The summary includes:\n",
    "      - Data Type\n",
    "      - Non Null Count\n",
    "      - Null Count\n",
    "      - Null Percentage\n",
    "      - Unique Values count\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Data Type': df.dtypes,\n",
    "        'Non Null Count': df.count(),\n",
    "        'Null Count': df.isna().sum(),\n",
    "        'Null Percentage': (df.isna().sum() / len(df) * 100).round(2),\n",
    "        'Unique Values': [df[col].nunique() for col in df.columns],\n",
    "    })\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path.cwd().parent.parent.parent.parent.parent.parent.parent.parent\n",
    "SAVE_DIR_EXTRACT_EXCEL = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"excel\"/ \"CORTE 2_20250410_194426.xlsx\"\n",
    "SAVE_DIR_EXTRACT_SGA_335 = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sga_335\" / \"sga_reporte_30-03-2025_06-04-2025_20250410_173936.xlsx\"\n",
    "CID_CUISMP_PATH = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"sharepoint_cid_cuismp\" / \"MINPU - CID-CUISMP - AB.xlsx\"\n",
    "DIR_PARADAS_RELOJ = BASE_DIR / \"media\" / \"minpub\" / \"validator_report\" / \"extract\" / \"pausa_cliente\" / \"sga_reporte_30-03-2025_04-04-2025_20250410_195338.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corte_excel = pd.read_excel(SAVE_DIR_EXTRACT_EXCEL, skipfooter=2, engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df_excel2 = get_dataframe_summary(df_corte_excel)\n",
    "df_corte_excel = cut_decimal_part(df_corte_excel, 'CUISMP')\n",
    "\n",
    "#info_df_excel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corte_excel = handle_null_values(df_corte_excel)\n",
    "info_df_excel2 = get_dataframe_summary(df_corte_excel)\n",
    "info_df_excel2\n",
    "#df_corte_excel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df_corte_excel[df_corte_excel['TICKET'] == 21784197 ]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335 = pd.read_excel(SAVE_DIR_EXTRACT_SGA_335)\n",
    "info_df_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_df_335\n",
    "row = df_sga_dinamico_335[df_sga_dinamico_335['nro_incidencia'] == 21789943]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sga_dinamico_335.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sga_dinamico_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335['interrupcion_inicio'] = pd.to_datetime(df_sga_dinamico_335['interrupcion_inicio'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['interrupcion_fin'] = pd.to_datetime(df_sga_dinamico_335['interrupcion_fin'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fecha_comunicacion_cliente'] = pd.to_datetime(df_sga_dinamico_335['fecha_comunicacion_cliente'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fecha_generacion'] = pd.to_datetime(df_sga_dinamico_335['fecha_generacion'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['fg_padre'] = pd.to_datetime(df_sga_dinamico_335['fg_padre'], errors='coerce', dayfirst=True)\n",
    "df_sga_dinamico_335['hora_sistema'] = pd.to_datetime(df_sga_dinamico_335['hora_sistema'], errors='coerce', dayfirst=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sga_dinamico_335 = handle_null_values(df_sga_dinamico_335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sga_dinamico_335 = get_dataframe_summary(df_sga_dinamico_335)\n",
    "info_sga_dinamico_335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sga_dinamico_335['tipificacion_interrupcion_hhmm'] = df_sga_dinamico_335['tipificacion_interrupcion'].apply(float_to_hhmm)\n",
    "row = df_sga_dinamico_335[df_sga_dinamico_335['nro_incidencia'] == 21789943 ]\n",
    "row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paradas_reloj = pd.read_excel(DIR_PARADAS_RELOJ)\n",
    "info_parada_reloj = get_dataframe_summary(df_paradas_reloj)\n",
    "info_parada_reloj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paradas_reloj.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paradas_reloj['startdate'] = pd.to_datetime(df_paradas_reloj['startdate'], errors=\"coerce\", dayfirst=True)\n",
    "df_paradas_reloj['enddate'] = pd.to_datetime(df_paradas_reloj['enddate'], errors=\"coerce\", dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_parada_reloj = get_dataframe_summary(df_paradas_reloj)\n",
    "info_parada_reloj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paradas_reloj.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.join(notebook_dir, '..','..','..','..','..','..','..','..')\n",
    "sys.path.append(os.path.abspath(project_root))\n",
    "\n",
    "\n",
    "print(\"notebook dir:\", notebook_dir)\n",
    "print(\"project root:\", project_root)\n",
    "print(\"absolute project root:\", os.path.abspath(project_root))\n",
    "print(\"notebook dir:\", sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.join(notebook_dir, '..')\n",
    "sys.path.append(os.path.abspath(project_root))\n",
    "\n",
    "sys.path.append(r\"\")\n",
    "\n",
    "from utils.logger_config import get_sga_logger\n",
    " \n",
    "logger = get_sga_logger()\n",
    "\n",
    "def resolve_clock_stop_overlaps(clock_stops: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Eliminate overlaps in clock stops (paradas de reloj) by nro_incidencia.\n",
    "\n",
    "    Args:\n",
    "        clock_stops: List of clock stops with 'start' 'end' datetime and 'nro_incidencia'\n",
    "\n",
    "    Returns:\n",
    "        List of non-overlapping clock stops\n",
    "            \n",
    "    \"\"\"\n",
    "    if not clock_stops:\n",
    "        return []\n",
    "    \n",
    "    incidents = {}\n",
    "    for stop in clock_stops:\n",
    "        nro_incidencia = stop.get('nro_incidencia', 'unknown')\n",
    "        if nro_incidencia not in incidents:\n",
    "            incidents[nro_incidencia] = []\n",
    "        incidents[nro_incidencia].append(stop)\n",
    "\n",
    "    \n",
    "    resolved_all = []   \n",
    "\n",
    "    for nro_incidencia, incident_stops in incidents.items():\n",
    "        sorted_stops = sorted(incident_stops, key=lambda x: x['start'])\n",
    "\n",
    "        for i, stop in enumerate(sorted_stops):\n",
    "            if pd.isna(stop['end']):\n",
    "                if i < len(sorted_stops) - 1 and not pd.isna(sorted_stops[i+1]['start']):\n",
    "                    stop['end'] = sorted_stops[i+1]['start']\n",
    "                else:\n",
    "                    logger.warning(f\"Removing stop with missing end date for nro_incidencia {nro_incidencia}\")\n",
    "                    continue\n",
    "        \n",
    "        valid_stops = [stop for stop in sorted_stops if not pd.isna(stop['end'])]\n",
    "\n",
    "        if not valid_stops:\n",
    "            continue\n",
    "\n",
    "        resolved_stops = [valid_stops[0]]\n",
    "\n",
    "        for current_stop in valid_stops[1:]:\n",
    "            last_resolved = resolved_stops[-1]\n",
    "\n",
    "            if current_stop['start'] <= last_resolved['end']:\n",
    "                last_resolved['end'] = max(last_resolved['end'], current_stop['end'])\n",
    "            else:\n",
    "                resolved_stops.append(current_stop)\n",
    "\n",
    "        resolved_all.extend(resolved_stops)\n",
    "\n",
    "    return resolved_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_total_clock_stop_minutes(\n",
    "    nro_incidencia:str,\n",
    "    interruption_start: datetime,\n",
    "    interruption_end: datetime,\n",
    "    df_sga_paradas: pd.DataFrame\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the total clock minutes for a ticket, considering constraints.\n",
    "\n",
    "    Args:\n",
    "        nro_incidencia: The ticket identifier\n",
    "        interrupcion_inicio: Start time of the interruption from REPORTE DINAMICO 335 \n",
    "        interrupcion_fin: End time of the interruption from REPORTE DINAMICO 335 \n",
    "    \n",
    "    Returns:\n",
    "        Total clock stop minutes\n",
    "    \n",
    "    \"\"\"   \n",
    "    df_sga_paradas['nro_incidencia'] = df_sga_paradas['nro_incidencia'].astype(str)\n",
    "    nro_incidencia_stops = df_sga_paradas[df_sga_paradas['nro_incidencia'] == nro_incidencia].copy()\n",
    "\n",
    "    if nro_incidencia_stops.empty:\n",
    "        logger.info(f\"No clock stops found for incident {nro_incidencia}\")\n",
    "        return 0.0\n",
    "    \n",
    "    clock_stops = []\n",
    "\n",
    "    for _, stop in nro_incidencia_stops.iterrows():\n",
    "        start_date = stop.get('startdate')\n",
    "        end_date = stop.get('enddate')\n",
    "\n",
    "        if pd.isna(start_date):\n",
    "            logger.warning(f\"Skipping record with missing start date for incident {nro_incidencia}\")\n",
    "            continue\n",
    "\n",
    "        if start_date < interruption_start:\n",
    "            logger.info(f\"Adjusting start time to interruption en for incident {nro_incidencia}\")\n",
    "            start_date = interruption_start\n",
    "\n",
    "        if not pd.isna(end_date):\n",
    "            if end_date > interruption_end:\n",
    "                logger.info(f\"Adjusting end time to interruption en for incident {nro_incidencia}\")\n",
    "                end_date = interruption_end\n",
    "\n",
    "            if start_date < end_date:\n",
    "                clock_stops.append({\n",
    "                    'start': start_date,\n",
    "                    'end': end_date,\n",
    "                    'nro_incidencia': nro_incidencia\n",
    "                })\n",
    "        else:\n",
    "            clock_stops.append({\n",
    "                'start': start_date,\n",
    "                'end': end_date,\n",
    "                'nro_incidencia': nro_incidencia\n",
    "            })\n",
    "    resolved_stops = resolve_clock_stop_overlaps(clock_stops)\n",
    "\n",
    "    total_minutes = sum(\n",
    "        (stop['end'] - stop['start']).total_seconds() / 60\n",
    "        for stop in resolved_stops\n",
    "        if not pd.isna(stop['end']) and not pd.isna(stop['start'])\n",
    "    )\n",
    "    return total_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_objetivos_tiempo(\n",
    "        df_corte_excel: pd.DataFrame,\n",
    "        df_sga_dinamico_335: pd.DataFrame,\n",
    "        df_sga_paradas: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges:\n",
    "        - corte_excel with sga_dinamico 335 on 'nro_incidencia'\n",
    "        - Summarizes the total \"paradas de reloj\" from sga_dinamico 380\n",
    "           and merges that as well\n",
    "    Returns a merged Dataframe with all columns needed for TIEMPO (HH:MM) validation.    \n",
    "    \"\"\"\n",
    "\n",
    "    df_corte_excel = df_corte_excel.rename(columns={'TICKET':'nro_incidencia'})\n",
    "   \n",
    "    df_corte_excel['nro_incidencia'] = df_corte_excel['nro_incidencia'].astype(str)\n",
    "    df_sga_dinamico_335['nro_incidencia'] = df_sga_dinamico_335['nro_incidencia'].astype(str)\n",
    "\n",
    "    merged_sga_335_excel = pd.merge(\n",
    "        df_corte_excel,\n",
    "        df_sga_dinamico_335,\n",
    "        on='nro_incidencia',\n",
    "        how='left',\n",
    "        indicator=True,\n",
    "        suffixes=('_corte_excel', '_sga_dinamico_335')\n",
    "    )\n",
    "\n",
    "    merged_sga_335_excel['sum_paradas'] = merged_sga_335_excel.apply(\n",
    "        lambda r: calculate_total_clock_stop_minutes(\n",
    "            nro_incidencia = r[\"nro_incidencia\"],\n",
    "            interruption_start = r[\"interrupcion_inicio\"],\n",
    "            interruption_end = r[\"interrupcion_fin\"],\n",
    "            df_sga_paradas = df_sga_paradas\n",
    "        ),\n",
    "        axis= 1\n",
    "    )\n",
    "    return merged_sga_335_excel\n",
    "\n",
    "df_merge_sga_335_corte_excel_paradas = merge_objetivos_tiempo(df_corte_excel, df_sga_dinamico_335, df_paradas_reloj)\n",
    "df_merge_sga_335_corte_excel_paradas\n",
    "unmatched_rows = df_merge_sga_335_corte_excel_paradas[df_merge_sga_335_corte_excel_paradas['_merge'] == 'both']\n",
    "unmatched_rows\n",
    "df_merge_sga_335_corte_excel_paradas_handleded_null = handle_null_values(df_merge_sga_335_corte_excel_paradas)\n",
    "df_merge_sga_335_corte_excel_paradas_handleded_null\n",
    "unmatched_rows['codincidencepadre'].dtype\n",
    "df_sga_dinamico_335['codincidencepadre'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_objetivo_14 = get_dataframe_summary(df_merge_sga_335_corte_excel_paradas_handleded_null)\n",
    "info_objetivo_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def subvalidation_tiempo_HHMM_paradas_cliente(df_merged: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Validatess  the 'TIEMPO (HH:MM)' column CORTE-EXCEL by comparing:\n",
    "    - (interruppcion_fin - interrupcion) - sum(paradas)\n",
    "    vs.\n",
    "    - The parsed minutes of 'TIEMPO(HH:MM)'.\n",
    "    Returns a Dataframe with boolean flags and 'fail_count'. \n",
    "    \"\"\"\n",
    "\n",
    "    df = df_merged.copy()\n",
    "    \n",
    "    df['Expected_Inicio'] = np.where(df['masivo'] == \"Si\",\n",
    "                                     df['fecha_generacion'],\n",
    "                                     df['interrupcion_inicio'])\n",
    "    \n",
    "    df['Expected_Inicio_trimmed'] = df['Expected_Inicio'].apply(lambda x: x.replace(second=0))\n",
    "    df['interrupcion_fin_trimmed'] = df['interrupcion_fin'].apply(lambda x: x.replace(second=0))\n",
    "\n",
    "    df['diff_335_min'] = (\n",
    "        (df['interrupcion_fin_trimmed'] - df['Expected_Inicio_trimmed'])\n",
    "        .dt.total_seconds()/60\n",
    "    )\n",
    "\n",
    "    def parse_hhmm_to_minutes(hhmm_str):\n",
    "        if pd.isna(hhmm_str):\n",
    "            return np.nan\n",
    "        try:\n",
    "            h,m = str(hhmm_str).split(':')\n",
    "            total_minutes = float(h)*60 + float(m)\n",
    "            print(f\"Converted {hhmm_str} to {total_minutes} minutes\")\n",
    "            return total_minutes\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {hhmm_str}: {e}\")\n",
    "            return np.nan\n",
    "        \n",
    "    df['TIEMPO (HH:MM)_trimed'] = df['TIEMPO (HH:MM)'].apply(\n",
    "        lambda x: str(x)[:5] if isinstance(x, str) and x.endswith(\":00\") else x\n",
    "    )\n",
    "    \n",
    "    \n",
    "    df['tiempo_corte_min'] = df['TIEMPO (HH:MM)_trimed'].apply(parse_hhmm_to_minutes)\n",
    "    \n",
    "    df['effective_time_335'] = df['diff_335_min'] - df['sum_paradas']\n",
    "\n",
    "    df['non_negative_335'] = df['diff_335_min'] >= 0\n",
    "    df['non_negative_paradas'] = df['sum_paradas'] >= 0\n",
    "    df['non_negative_effective'] = df['effective_time_335'] >= 0\n",
    "\n",
    "    tolerance = 1e-9\n",
    "\n",
    "    df['match_corte'] = (\n",
    "        (df['tiempo_corte_min'] - df['effective_time_335'])\n",
    "        .abs() < tolerance\n",
    "    )\n",
    "\n",
    "    df['Validation_OK'] = (\n",
    "        df['non_negative_335'] &\n",
    "        df['non_negative_paradas'] &\n",
    "        df['non_negative_effective'] &\n",
    "        df['match_corte']\n",
    "    )\n",
    "\n",
    "    df['fail_count'] = (\n",
    "        (~df['non_negative_335']).astype(int) + \n",
    "        (~df['non_negative_paradas']).astype(int) + \n",
    "        (~df['non_negative_effective']).astype(int) +\n",
    "        (~df['match_corte']).astype(int)\n",
    "    \n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "df_validation_paradas = subvalidation_tiempo_HHMM_paradas_cliente(df_merge_sga_335_corte_excel_paradas)\n",
    "#df_validation_paradas.head(1)\n",
    "row = df_validation_paradas[df_validation_paradas['nro_incidencia'] == \"21793172\" ]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_valida_paradas = get_dataframe_summary(df_validation_paradas)\n",
    "#info_valida_paradas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def buid_failure_messages_tiempo_HHMM_paradas_cliente(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Builds a descriptive message for the 'TIEMPO (HH:MM)' validation.\n",
    "    Returns rows that fail any check (fall_count > 0) with columns:\n",
    "    -'numero de incidencia'\n",
    "    -'mensaje'\n",
    "    -'objetivo'\n",
    "    \n",
    "    \"\"\"\n",
    "    mensaje = np.where(\n",
    "        df['Validation_OK'],\n",
    "        \"Validation de TIEMPO (HH:MM) exitosa\",\n",
    "        (\n",
    "            np.where(~df['non_negative_335'],\n",
    "                     \"INTERRUPCION_FIN - INTERRUPCION_INICIO es negativo. \",  \"\")+\n",
    "            np.where(~df['non_negative_paradas'],\n",
    "                     \"Suma de paradas de reloj es negativa. \", \"\")+\n",
    "            np.where(~df['non_negative_effective'],\n",
    "                     \"Tiempo efectivo (INTERRUPCION - paradas) es negativo.\", \"\")+\n",
    "            np.where(~df['match_corte'],\n",
    "                     \"EL TIEMPO (HH:MM): \" + df['tiempo_corte_min'].astype(str) +\n",
    "                       \" de CORTE EXCEL  no coincide con el tiempo efectivo calculado SGA: \" +df['effective_time_335'].astype(str)  , \"\")\n",
    "        )\n",
    "    )\n",
    "    df['mensaje'] = mensaje\n",
    "    df['objetivo'] = 1.4\n",
    "\n",
    "    df_failures = df[df['fail_count'] > 0 ]\n",
    "    return df_failures[['nro_incidencia', 'mensaje', 'TIPO REPORTE','objetivo']]\n",
    "    \n",
    "df_mensaje_paradas = buid_failure_messages_tiempo_HHMM_paradas_cliente(df_validation_paradas)\n",
    "df_mensaje_paradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row = df_merge_sga_335_corte_excel[df_merge_sga_335_corte_excel['nro_incidencia'] == \"21784197\" ]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
